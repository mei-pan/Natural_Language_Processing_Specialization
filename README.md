<p align="center">
  <img src="https://github.com/mei-pan/Natural_Language_Processing_Specialization/blob/main/NLP_shutterstock_raindrop74-1507366230.jpg" alt="Image description" width='auto', height='200'>
</p>


# Natural Language Processing Specialization [Link](https://www.coursera.org/specializations/natural-language-processing).
  This specialization is a series of 4 courses offered by Deeplearning.ai focuses on cutting-edge NLP techniques.
  
## Course 1: NLP with Classification and Vector Spaces  [Link](https://www.coursera.org/learn/classification-vector-spaces-in-nlp?specialization=natural-language-processing)
  Objective: Using logistic regression, na√Øve Bayes and word vector to implement sentiment analysis, complete analogies and word translation.  
  
 #### Week 1: 
 Learn to extract features from text into numerical vectors, then build a sentiment analysis model for tweets using a logistic regression!
  
  &nbsp;&nbsp;&nbsp;&nbsp; __***Assignment***__: Logistic Regression [Link](https://github.com/mei-pan/Natural_Language_Processing_Specialization/blob/main/NLP_C1_W1_Logistic_Regression/C1_W1_Assignment.ipynb).      
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Sentiment analysis of tweets with Logistc Regression.  
   
      
      
#### Week 2: 
Learn the theory behind Bayes' rule for conditional probabilities, then apply it toward building a Naive Bayes model for sentiment analysis
  &nbsp;&nbsp;&nbsp;&nbsp; __***Assignment***__: Naive Bayes  [Link](https://github.com/mei-pan/Natural_Language_Processing_Specialization/blob/main/NLP_C1_W2_Naive_Bayes/C1_W2_Assignment.ipynb)  
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Sentiment analysis of tweets with Naive Bayes model.
   
   
#### Week 3:
understand vectors spaces, ways to ultilize euclidean distance and cosine similiarity to find similar and dissimilar items with embeddings and PCA.    
  &nbsp;&nbsp;&nbsp;&nbsp; __***Assignment***__: Vector Space Model & PCA [Link](https://github.com/mei-pan/Natural_Language_Processing_Specialization/blob/main/NLP_C1_W3_Vector_Space_Model/C1_W3_Assignment.ipynb).       
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Ultilize vector space and vector embeddings to build a function that predict the name of capital the city given the country name.   
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- project also include building a functions that computes PCA. 
    
#### Week 4: 
Learn to transform word vectors and assign them to subsets using locality sensitive hashing, in order to perform machine translation and document search.      
  &nbsp;&nbsp;&nbsp;&nbsp; __***Assignment***__: Machine Translation and LSH (Local Sensitive Hashing) [Link](https://github.com/mei-pan/Natural_Language_Processing_Specialization/blob/main/NLP_C1_W4_Naive_Machine_Translation_and_LSH/C1_W4_Assignment.ipynb)   
  

## Course 2: Natural Language Processing with Probabilstic Models 
#### Week 1: 
Learn about autocorrect, minimum edit distance, and dynamic programming, then build a spellchecker to correct misspelled words!  
  &nbsp;&nbsp;&nbsp;&nbsp; __***Assignment***__: Autocorrection [Link](https://github.com/mei-pan/Natural_Language_Processing_Specialization/blob/main/NLP_C2_W1_Autocorrect/NLP_C2_W1_Autocorrect.ipynb).      
 
#### Week 2: 
Learn about Markov and Hidden Markov Models as well as Viterbi Algorithm to create a part-of-speech(POS) tags for a Wall Street Journal text corpus.   
  &nbsp;&nbsp;&nbsp;&nbsp; __***Assignment***__: POS Tagging [Link](https://github.com/mei-pan/Natural_Language_Processing_Specialization/blob/main/NLP_C2_W2_POS_Tagging/C2_W2_Assignment.ipynb).      
 
#### Week 3: 
Learn about how N-gram language models work by calculating sequence probabilities, then build an autocomplete language model using a text corpus from Twitter!   
  &nbsp;&nbsp;&nbsp;&nbsp; __***Assignment***__: Autocomplete [Link]().      
 


  
## Course 3: Natural Language Processing in TensorFlow

## Course 4: Sequences, Time Series and Prediction 
